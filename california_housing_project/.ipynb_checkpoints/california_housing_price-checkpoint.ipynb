{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abec8af4",
   "metadata": {},
   "source": [
    "    GETTING, EXPLORING AND CLEANING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5463ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d46ac8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fetch the data\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1e07537",
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno -2] Name or service not known>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1353\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1355\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    923\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6660/1976996646.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfetch_housing_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# when fetch_housing_data() is called, it creates a datasets/housing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# directory in your workspace and downloads the housing.tgz file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6660/3676792410.py\u001b[0m in \u001b[0;36mfetch_housing_data\u001b[0;34m(housing_url, housing_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtgz_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"housing.tgz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhousing_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgz_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mhousing_tgz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgz_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mhousing_tgz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhousing_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    543\u001b[0m                                   '_open', req)\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1398\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -2] Name or service not known>"
     ]
    }
   ],
   "source": [
    "fetch_housing_data()\n",
    "# when fetch_housing_data() is called, it creates a datasets/housing \n",
    "# directory in your workspace and downloads the housing.tgz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the data\n",
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d40c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da829b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the describe() method shows a summary of the numerical attributes\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973afa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e805d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a histogram for each numerical attribute\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins = 50, figsize = (20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For illustration only. Sklearn has train_test_split()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcce986",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = split_train_test(housing, 0.2)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f13846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting using train_test_split from sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329abc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(train_set), \"train +\", len(test_set), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d570573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there should not be too many strata, and each stratum should be large enough\n",
    "# this code creates an income category attribute by dividing the median income by 1.5(to limit the number of income categories), and rounding up using ceil(to have discrete categories), and then merging all the categories greater than 5 into category 5:\n",
    "\n",
    "housing['income_cat'] = np.ceil(housing['median_income'] / 1.5)\n",
    "housing['income_cat'].where(housing['income_cat'] < 5, 5.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of income categories\n",
    "\n",
    "housing['income_cat'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c28e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified sampling based on the income category\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the stratification in the income category proportions in the full housing dataset:\n",
    "\n",
    "housing[\"income_cat\"].value_counts() / len(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ff09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for sampling bias \n",
    "\n",
    "def income_cat_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": income_cat_proportions(housing),\n",
    "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "    \"Random\": income_cat_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573550c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampling the bias comparison of stratified versus purely random sampling\n",
    "\n",
    "compare_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we remove the income_cat attribute so the data is back to its original state\n",
    "\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8c95b",
   "metadata": {},
   "source": [
    "DISCOVER AND VISUALIZE THE DATA TO GAIN INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019ed06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy so we can work with it without harming the training set\n",
    "\n",
    "housing = strat_train_set.copy()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807178e5",
   "metadata": {},
   "source": [
    "DISCOVER AND VISUALIZE THE DATA TO GAIN INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9930f12d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geographical scatterplot of the data\n",
    "\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e59005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# better visualization, highlighting high-density areas\n",
    "\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bdcab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# california housing prices\n",
    "#1. radius of each circle represents the district's population \n",
    "#2. color represents the price\n",
    "#3. we use a predefined color map, called jet, which ranges from the (low values) to red (high values)\n",
    "\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "    sharex=False)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0826da",
   "metadata": {},
   "source": [
    "LOOKING FOR CORRELATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a90c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the standard correlation coefficient between every pair of attributes using the corr() method\n",
    "\n",
    "corr_matrix = housing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b3260f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking how much each attribute correlates with the median house value\n",
    "\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f4c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter matrix \n",
    "\n",
    "# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "              \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b6690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# median income vs median house value\n",
    "# the most promising attribute to predict the median house value is the median income\n",
    "\n",
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
    "             alpha=0.1)\n",
    "plt.axis([0, 16, 0, 550000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89119a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating some new useful attributes\n",
    "\n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4287a8d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking the correlation matrix again\n",
    "\n",
    "corr_matrix = housing.corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda3b56",
   "metadata": {},
   "source": [
    "    PREPARE THE DATA FOR MACHINE LEARNING ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed26c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8cb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the simpleImputer to fill in the missing values\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce32d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the median can only be computed on numerical attributes, we need to create a copy of the data without the text attribute ocean_proximity \n",
    "\n",
    "housing_num = housing.drop('ocean_proximity', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aec5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the imputer instance to the training data set using fit()\n",
    "\n",
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8baba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually checking the imputer statistics is the same as the median of each attribute\n",
    "\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num.median().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the \"trained\" imputer to transform the training set\n",
    "\n",
    "X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it back into a pandas dataframe\n",
    "\n",
    "housing_tr = pd.DataFrame(X, columns = housing_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de028e7",
   "metadata": {},
   "source": [
    "    HANDLING TEXT AND CATEGORICAL ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f351fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we convert the text labels to numbers\n",
    "\n",
    "housing_cat = housing[['ocean_proximity']]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61df1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]\n",
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d715c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we convert integer categorical values into one-hot vectors\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c228889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, the OneHotEncoder class returns a sparse array, but we can convert it to a dense array if needed by calling the toarray() method:\n",
    "\n",
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682db27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c444327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64c039",
   "metadata": {},
   "source": [
    "CUSTOM TRANSFORMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62a52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we write our own specific transformer for custom cleanup operations or combining specific attributes\n",
    "# in this example, the transformer has one hyperparameter, add_bedrooms_per_room, set to True by default\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# get the right column indices: safer than hard-coding indices 3, 4, 5, 6\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = [\n",
    "    list(housing.columns).index(col)\n",
    "    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kwargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46a11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_extra_attribs = pd.DataFrame(\n",
    "    housing_extra_attribs,\n",
    "    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"],\n",
    "    index=housing.index)\n",
    "housing_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dd8a46e",
   "metadata": {},
   "source": [
    "TRANSFORMATION PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many data transformation steps that need to be executed in the right order\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "housing_num_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transformer to automatically extract the numerical columns into a NumPy array. \n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8333b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we join all these components into a big pipeline that will preprocess both the numerical and the categorical features\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d71373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we join the two pipelines into a single pipeline by using sklearn's FeatureUnion class\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8409d92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "housing_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b99ea",
   "metadata": {},
   "source": [
    "SELECT AND TRAIN A MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65feee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with a linear regression model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b349fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try the full preprocessing pipeline on a few training instances\n",
    "\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54752e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure this model's RMSE on the whole training set \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37844ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure this model's mean absolute error on the whole training set \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(housing_labels, housing_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the results are not too satisfying, we choose a more powerful model (decision tree regressor)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the trained model on the training set\n",
    "\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a6b0c7",
   "metadata": {},
   "source": [
    "BETTER EVALUATION USING CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c122176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as our model is overfitting we cross validate our findings\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring='neg_mean_squared_error', cv =10)\n",
    "tree_rsme_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec8fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# simple function to display the scores\n",
    "\n",
    "def display_scores(scores):\n",
    "    print('Scores: ', scores)\n",
    "    print('Mean: ', scores.mean())\n",
    "    print('Standard Devitation: ', scores.std())\n",
    "    \n",
    "display_scores(tree_rsme_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb679ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the scores for linear regression\n",
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using random forest regressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52b2cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# computing the scores for random forest classifier\n",
    "\n",
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving a general idea of the entire scores\n",
    "\n",
    "scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "pd.Series(np.sqrt(-scores)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c5336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying support vector regression\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = svm_reg.predict(housing_prepared)\n",
    "svm_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9a1c7",
   "metadata": {},
   "source": [
    "FINE TUNING OUR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e5d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to find a great combination of hyperparameter values\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60acf54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the best combination of parameters\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007753a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the best estimator directly\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f058ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluation scores\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
